# -*- coding: utf-8 -*-
"""app_ventas_retail

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jAwj2rrGzvOaXh5ZIeaAclWBGQsq9IAq

# 1.2 Ejercicio 1: Creación de Pipeline ML Automatizado en Google Colab

Paso 0: Creacion de Dataset
"""

# Celda ejecutable para generar el dataset en la carpeta /content/
import pandas as pd
import numpy as np
import os
# Asegurar que exista la carpeta /content
os.makedirs("content", exist_ok=True)
# Reproducibilidad
np.random.seed(42)
# Parámetros generales
n_tiendas = 50
semanas = 104 # 2 años
fechas = pd.date_range(start="2022-01-03", periods=semanas, freq="W-MON")
tiendas = range(1, n_tiendas + 1)
data = []
for tienda_id in tiendas:
    base_ventas = np.random.normal(15000, 3000)
    for fecha in fechas:
        promocion = np.random.choice([0, 1], p=[0.7, 0.3])
        inventario = np.random.normal(50000, 10000)
        temperatura = np.random.normal(20, 8)
        ventas = (
            base_ventas
            + promocion * np.random.normal(3000, 800)
            + (inventario / 10000) * np.random.normal(200, 50)
            - abs(temperatura - 20) * np.random.normal(50, 10)
            + np.random.normal(0, 1000)
        )
        data.append({
            "tienda_id": tienda_id,
            "fecha": fecha,
            "ventas_semanales": max(0, round(ventas, 2)),
            "promocion_activa": promocion,
            "inventario_inicial": max(0, round(inventario, 0)),
            "temperatura_promedio": round(temperatura, 1)
        })
# Crear DataFrame
df = pd.DataFrame(data)
# Ruta de salida
ruta_salida = "content/tema1_ventas_retail.csv"
# Guardar CSV
df.to_csv(ruta_salida, index=False)
df.head(), df.shape, f"Archivo generado en: {ruta_salida}"

"""Paso 1: Configuración del Entorno"""

# Instala las librerías necesarias
!pip install plotly pandas scikit-learn
# Importa las librerías
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import pickle

"""Paso 2: Configuración Centralizada de Parámetros"""

# Configuración centralizada-modifica aquí para cambiar todo el pipeline
CONFIG = {
    'data_path': 'content/tema1_ventas_retail.csv',
    'model_params': {
    'n_estimators': 100,
    'random_state': 42,
    'max_depth': 10
    },
    'test_size': 0.2,
    'target_column': 'ventas_semanales',
    'date_column': 'fecha',
    'store_column': 'tienda_id'
}
print("Configuración cargada correctamente")
print(f"Modelo objetivo: {CONFIG['target_column']}")

"""Paso 3: Función de Carga y Validación de Datos"""

def cargar_y_validar_datos(ruta_archivo):
    """
    Carga y valida los datos de entrada
    """
    try:
        # Cargar datos
        df = pd.read_csv(ruta_archivo)
        print(f"Datos cargados: {df.shape[0]} filas, {df.shape[1]} columnas")
        # Validaciones básicas
        columnas_requeridas = [CONFIG['target_column'], CONFIG['date_column'], CONFIG['store_column']]
        for col in columnas_requeridas:
            if col not in df.columns:
                raise ValueError(f"Columna requerida '{col}' no encontrada")
        # Convertir fecha
        df[CONFIG['date_column']] = pd.to_datetime(df[CONFIG['date_column']])
        # Verificar valores faltantes en target
        if df[CONFIG['target_column']].isnull().sum() > 0:
            print(f"Advertencia: {df[CONFIG['target_column']].isnull().sum()} valores faltantes en target")
        print("Validación de datos completada")
        return df
    except Exception as e:
        print(f"Error al cargar datos: {e}")
        return None
# Ejecutar función
df = cargar_y_validar_datos(CONFIG['data_path'])

"""Paso 4: Función de Preprocesamiento"""

def preprocesar_datos(df):
    """
    Preprocesa los datos para el modelo
    """
    print("Iniciando preprocesamiento...")
    # Crear features temporales
    df['año'] = df[CONFIG['date_column']].dt.year
    df['mes'] = df[CONFIG['date_column']].dt.month
    df['semana'] = df[CONFIG['date_column']].dt.isocalendar().week
    df['dia_semana'] = df[CONFIG['date_column']].dt.dayofweek
    # Seleccionar features para el modelo
    feature_columns = ['tienda_id', 'año', 'mes', 'semana', 'dia_semana',
                       'promocion_activa', 'inventario_inicial', 'temperatura_promedio']
    # Verificar que todas las features existan
    features_disponibles = [col for col in feature_columns if col in df.columns]
    print(f"Features disponibles: {features_disponibles}")
    X = df[features_disponibles]
    y = df[CONFIG['target_column']]
    print(f"Preprocesamiento completado: {X.shape[1]} features")
    return X, y
# Ejecutar preprocesamiento
X, y = preprocesar_datos(df)

"""Paso 5: Función de Entrenamiento y Evaluación"""

def entrenar_y_evaluar_modelo(X, y):
    """
    Entrena el modelo y calcula métricas
    """
    print("Iniciando entrenamiento del modelo...")
    # Dividir datos
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=CONFIG['test_size'], random_state=42
    )
    # Entrenar modelo
    modelo = RandomForestRegressor(**CONFIG['model_params'])
    modelo.fit(X_train, y_train)
    # Hacer predicciones
    y_pred = modelo.predict(X_test)
    # Calcular métricas
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    metricas = {
        'mae': mae,
        'r2': r2,
        'fecha_entrenamiento': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }
    print(f"Modelo entrenado exitosamente")
    print(f"MAE: {mae:.2f}")
    print(f"R²: {r2:.3f}")
    return modelo, metricas, y_test, y_pred
# Ejecutar entrenamiento
modelo, metricas, y_test, y_pred = entrenar_y_evaluar_modelo(X, y)

"""Paso 6: Función de Guardado del Modelo"""

def guardar_modelo_y_metricas(modelo, metricas):
    """
    Guarda el modelo y sus métricas
    """
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    # Guardar modelo
    nombre_modelo = f'modelo_ventas_{timestamp}.pkl'
    with open(nombre_modelo, 'wb') as f:
        pickle.dump(modelo, f)
    # Guardar métricas
    nombre_metricas = f'metricas_ventas_{timestamp}.txt'
    with open(nombre_metricas, 'w') as f:
        for key, value in metricas.items():
            f.write(f"{key}:{value}\n")
    print(f"Modelo guardado como: {nombre_modelo}")
    print(f"Métricas guardadas como: {nombre_metricas}")
    return nombre_modelo, nombre_metricas
# Guardar modelo
archivo_modelo, archivo_metricas = guardar_modelo_y_metricas(modelo, metricas)

"""# 1.3 Ejercicio 2: Sistema de Reportes Automáticos con Visualizaciones
Paso 1: Configuración para Reportes
"""

# Configuración específica para reportes
REPORTE_CONFIG = {
    'titulo_empresa': 'RetailMax Analytics',
    'colores_corporativos': ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'],
    'template_plotly': 'plotly_white',
    'ruta_logo': None # Puedes agregar logo después
}
print("Configuración de reportes cargada")

"""Paso 2: Función para Métricas de Performance"""

def generar_metricas_performance(y_real, y_pred):
    """
    Genera métricas detalladas de performance del modelo
    """
    # Calcular métricas básicas
    mae = mean_absolute_error(y_real, y_pred)
    r2 = r2_score(y_real, y_pred)
    # Calcular métricas adicionales
    mape = np.mean(np.abs((y_real-y_pred) / y_real)) * 100
    rmse = np.sqrt(np.mean((y_real-y_pred) ** 2))
    # Calcular accuracy personalizada (predicciones dentro del 10%)
    accuracy_10pct = np.mean(np.abs((y_real-y_pred) / y_real) <= 0.1) * 100
    metricas_detalladas = {
        'MAE (Error Absoluto Medio)': f"{mae:.2f}",
        'R² (Coeficiente Determinación)': f"{r2:.3f}",
        'MAPE (Error Porcentual Medio)': f"{mape:.1f}%",
        'RMSE (Raíz Error Cuadrático)': f"{rmse:.2f}",
        'Accuracy ±10%': f"{accuracy_10pct:.1f}%"
    }
    return metricas_detalladas
# Generar métricas
metricas_detalladas = generar_metricas_performance(y_test, y_pred)
print("Métricas calculadas:")
for metrica, valor in metricas_detalladas.items():
    print(f" {metrica}: {valor}")

"""Paso 3: Visualización de Predicciones vs Reales"""

def crear_grafico_predicciones_vs_reales(y_real, y_pred):
    """
    Crea gráfico de dispersión predicciones vs valores reales
    """
    fig = go.Figure()
    # Scatter plot de predicciones vs reales
    fig.add_trace(go.Scatter(
        x=y_real,
        y=y_pred,
        mode='markers',
        name='Predicciones',
        marker=dict(
            color=REPORTE_CONFIG['colores_corporativos'][0],
            size=8,
            opacity=0.6
        ),
        hovertemplate='<b>Real:</b> %{x:.0f}<br><b>Predicción:</b> %{y:.0f}<extra></extra>'
    ))
    # Línea de predicción perfecta
    min_val = min(min(y_real), min(y_pred))
    max_val = max(max(y_real), max(y_pred))
    fig.add_trace(go.Scatter(
        x=[min_val, max_val],
        y=[min_val, max_val],
        mode='lines',
        name='Predicción Perfecta',
        line=dict(color='red', dash='dash', width=2)
    ))
    # Configurar layout
    fig.update_layout(
        title={
            'text': 'Predicciones vs Valores Reales-Modelo de Ventas',
            'x': 0.5,
            'font': {'size': 16}
        },
        xaxis_title='Ventas Reales',
        yaxis_title='Ventas Predichas',
        template=REPORTE_CONFIG['template_plotly'],
        showlegend=True,
        width=700,
        height=500
    )
    return fig
# Crear y mostrar gráfico
fig_predicciones = crear_grafico_predicciones_vs_reales(y_test, y_pred)
fig_predicciones.show()

"""Paso 4: Gráfico de Distribución de Errores"""

def crear_grafico_distribucion_errores(y_real, y_pred):
    """
    Crea histograma de la distribución de errores
    """
    errores = y_pred-y_real
    errores_porcentuales = ((y_pred-y_real) / y_real) * 100
    # Crear subplots
    from plotly.subplots import make_subplots
    fig = make_subplots(
        rows=1, cols=2,
        subplot_titles=('Distribución de Errores Absolutos', 'Distribución de Errores Porcentuales'),
        horizontal_spacing=0.1
    )
    # Histograma de errores absolutos
    fig.add_trace(
        go.Histogram(
            x=errores,
            nbinsx=30,
            name='Errores Absolutos',
            marker_color=REPORTE_CONFIG['colores_corporativos'][1],
            opacity=0.7
        ),
        row=1, col=1
    )
    # Histograma de errores porcentuales
    fig.add_trace(
        go.Histogram(
            x=errores_porcentuales,
            nbinsx=30,
            name='Errores Porcentuales',
            marker_color=REPORTE_CONFIG['colores_corporativos'][2],
            opacity=0.7
        ),
        row=1, col=2
    )
    # Configurar layout
    fig.update_layout(
        title={
            'text': 'Análisis de Errores del Modelo',
            'x': 0.5,
            'font': {'size': 16}
        },
        template=REPORTE_CONFIG['template_plotly'],
        showlegend=False,
        width=900,
        height=400
    )
    fig.update_xaxes(title_text="Error Absoluto", row=1, col=1)
    fig.update_xaxes(title_text="Error Porcentual (%)", row=1, col=2)
    fig.update_yaxes(title_text="Frecuencia", row=1, col=1)
    fig.update_yaxes(title_text="Frecuencia", row=1, col=2)
    return fig
# Crear y mostrar gráfico
fig_errores = crear_grafico_distribucion_errores(y_test, y_pred)
fig_errores.show()

"""Paso 5: Feature Importance Interactivo"""

def crear_grafico_feature_importance(modelo, feature_names):
    """
    Crea gráfico interactivo de importancia de features
    """
    # Obtener importancias
    importancias = modelo.feature_importances_
    # Crear DataFrame para ordenar
    df_importance = pd.DataFrame({
        'feature': feature_names,
        'importancia': importancias
    }).sort_values('importancia', ascending=True)
    # Crear gráfico de barras horizontal
    fig = go.Figure(go.Bar(
        x=df_importance['importancia'],
        y=df_importance['feature'],
        orientation='h',
        marker=dict(
            color=df_importance['importancia'],
            colorscale='Viridis',
            showscale=True,
            colorbar=dict(title="Importancia")
        ),
        hovertemplate='<b>%{y}</b><br>Importancia: %{x:.3f}<extra></extra>'
    ))
    fig.update_layout(
        title={
            'text': 'Importancia de Variables en el Modelo',
            'x': 0.5,
            'font': {'size': 16}
        },
        xaxis_title='Importancia',
        yaxis_title='Variables',
        template=REPORTE_CONFIG['template_plotly'],
        width=700,
        height=500
    )
    return fig
# Crear y mostrar gráfico
fig_importance = crear_grafico_feature_importance(modelo, X.columns)
fig_importance.show()

"""Paso 6: Función de Reporte Completo"""

def generar_reporte_completo(modelo, metricas, y_real, y_pred, feature_names):
    """
    Genera reporte HTML completo con todas las visualizaciones
    """
    from datetime import datetime
    # Crear HTML del reporte
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>Reporte de Performance - Modelo de Ventas RetailMax</title>
        <style>
            body {{ font-family: Arial, sans-serif; margin: 40px; }}
            .header {{ text-align: center; color: #1f77b4; }}
            .metrics {{ background-color: #f8f9fa; padding: 20px; border-radius: 5px; margin: 20px 0; }}
            .metric {{ display: inline-block; margin: 10px 20px; }}
            .timestamp {{ color: #666; font-size: 12px; }}
        </style>
    </head>
    <body>
        <div class="header">
            <h1>RetailMax Analytics</h1>
            <h2>Reporte de Performance-Modelo de Predicción de Ventas</h2>
            <p class="timestamp">Generado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </div>
        <div class="metrics">
            <h3>Métricas de Performance</h3>
    """
    # Agregar métricas
    for metrica, valor in metricas.items():
        html_content += f'<div class="metric"><strong>{metrica}:</strong> {valor}</div>'
    html_content += """
        </div>
        <h3>Visualizaciones</h3>
        <p>Las visualizaciones interactivas se han generado por separado. Incluye:</p>
        <ul>
            <li>Gráfico de Predicciones vs Valores Reales</li>
            <li>Distribución de Errores</li>
            <li>Importancia de Variables</li>
        </ul>
        <h3>Insights Clave</h3>
        <ul>
            <li>El modelo muestra un R² de {metricas['R² (Coeficiente Determinación)']}, indicando un buen ajuste</li>
            <li>El error porcentual promedio es de {metricas['MAPE (Error Porcentual Medio)']}</li>
            <li>El {metricas['Accuracy ±10%']} de las predicciones están dentro del ±10% del valor real</li>
        </ul>
        <h3>Recomendaciones</h3>
        <ul>
            <li>Continuar monitoreando el performance del modelo semanalmente</li>
            <li>Considerar reentrenamiento si el error aumenta significativamente</li>
            <li>Evaluar la incorporación de nuevas variables externas</li>
        </ul>
    </body>
    </html>
    """
    # Guardar reporte
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    nombre_reporte = f'reporte_ventas_{timestamp}.html'
    with open(nombre_reporte, 'w', encoding='utf-8') as f:
        f.write(html_content)
    print(f"Reporte HTML generado: {nombre_reporte}")
    return nombre_reporte
# Generar reporte completo
archivo_reporte = generar_reporte_completo(modelo, metricas_detalladas, y_test, y_pred, X.columns)

"""# 1.4 Ejercicio 3: Configuración de Ejecución Programada con Google Apps Script

Paso 1: Preparación del Notebook para Ejecución Automática
"""

# Configuración para ejecución automática
import os
from datetime import datetime, timedelta
import logging
# Configurar logging para ejecución automática
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s-%(levelname)s-%(message)s',
    handlers=[
        logging.FileHandler('ejecucion_automatica.log'),
        logging.StreamHandler()
    ]
)
def log_inicio_ejecucion():
    """Registra el inicio de la ejecución automática"""
    logging.info("="*50)
    logging.info("INICIO DE EJECUCIÓN AUTOMÁTICA")
    logging.info(f"Timestamp: {datetime.now()}")
    logging.info("="*50)
def log_fin_ejecucion(exitoso=True):
    """Registra el fin de la ejecución"""
    status = "EXITOSA" if exitoso else "FALLIDA"
    logging.info("="*50)
    logging.info(f"FIN DE EJECUCIÓN-{status}")
    logging.info(f"Timestamp: {datetime.now()}")
    logging.info("="*50)
# Iniciar logging
log_inicio_ejecucion()

"""Paso 2: Función de Verificación de Datos Nuevos"""

def verificar_datos_nuevos(ruta_archivo, dias_atras=7):
    """
    Verifica si hay datos nuevos en el archivo
    """
    try:
        df = pd.read_csv(ruta_archivo)
        df['fecha'] = pd.to_datetime(df['fecha'])
        # Verificar fecha más reciente
        fecha_mas_reciente = df['fecha'].max()
        fecha_limite = datetime.now() - timedelta(days=dias_atras)
        hay_datos_nuevos = fecha_mas_reciente >= fecha_limite
        logging.info(f"Fecha más reciente en datos: {fecha_mas_reciente}")
        logging.info(f"Fecha límite para considerar 'nuevos': {fecha_limite}")
        logging.info(f"¿Hay datos nuevos?: {hay_datos_nuevos}")
        return hay_datos_nuevos, fecha_mas_reciente
    except Exception as e:
        logging.error(f"Error verificando datos nuevos: {e}")
        return False, None
# Verificar datos
hay_nuevos, fecha_reciente = verificar_datos_nuevos(CONFIG['data_path'])

"""Paso 3: Pipeline Completo con Manejo de Errores"""

def ejecutar_pipeline_completo():
    """
    Ejecuta el pipeline completo con manejo de errores
    """
    try:
        logging.info("Iniciando pipeline completo...")
        # Paso 1: Cargar datos
        logging.info("Paso 1: Cargando datos...")
        df = cargar_y_validar_datos(CONFIG['data_path'])
        if df is None:
            raise Exception("Error al cargar datos")
        # Paso 2: Preprocesar
        logging.info("Paso 2: Preprocesando datos...")
        X, y = preprocesar_datos(df)
        # Paso 3: Entrenar modelo
        logging.info("Paso 3: Entrenando modelo...")
        modelo, metricas, y_test, y_pred = entrenar_y_evaluar_modelo(X, y)
        # Paso 4: Guardar modelo
        logging.info("Paso 4: Guardando modelo...")
        archivo_modelo, archivo_metricas = guardar_modelo_y_metricas(modelo, metricas)
        # Paso 5: Generar reporte
        logging.info("Paso 5: Generando reporte...")
        metricas_detalladas = generar_metricas_performance(y_test, y_pred)
        archivo_reporte = generar_reporte_completo(modelo, metricas_detalladas, y_test, y_pred, X.columns)
        # Paso 6: Notificar éxito
        logging.info("Pipeline ejecutado exitosamente")
        logging.info(f"Archivos generados:")
        logging.info(f"-Modelo: {archivo_modelo}")
        logging.info(f"-Métricas: {archivo_metricas}")
        logging.info(f"-Reporte: {archivo_reporte}")
        return True, {
            'modelo': archivo_modelo,
            'metricas': archivo_metricas,
            'reporte': archivo_reporte
        }
    except Exception as e:
        logging.error(f"Error en pipeline: {e}")
        return False, None
# Ejecutar pipeline si hay datos nuevos
if hay_nuevos:
    exito, archivos = ejecutar_pipeline_completo()
    log_fin_ejecucion(exito)
else:
    logging.info("No hay datos nuevos. Saltando ejecución.")
    log_fin_ejecucion(True)

"""Paso 6: Función de Monitoreo de Ejecuciones"""

def crear_log_ejecuciones():
    """
    Crea un sistema de logging para monitorear ejecuciones
    """
    log_data = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'exito': True, # Se actualizará según el resultado
        'duracion_minutos': 0, # Se calculará
        'archivos_generados': [],
        'metricas_modelo': {},
        'errores': []
    }
    return log_data
def guardar_log_ejecucion(log_data):
    """
    Guarda el log de ejecución en un archivo CSV
    """
    import csv
    import os
    archivo_log = 'historial_ejecuciones.csv'
    # Verificar si el archivo existe
    archivo_existe = os.path.exists(archivo_log)
    with open(archivo_log, 'a', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        # Escribir header si es archivo nuevo
        if not archivo_existe:
          writer.writerow(['timestamp', 'exito', 'duracion_minutos', 'archivos_generados', 'errores'])
        # Escribir datos
        writer.writerow([
            log_data['timestamp'],
            log_data['exito'],
            log_data['duracion_minutos'],
            ';'.join(log_data['archivos_generados']),
            ';'.join(log_data['errores'])
        ])
    print(f"Log guardado en {archivo_log}")
# Ejemplo de uso del sistema de logging
log_ejecucion = crear_log_ejecuciones()
# ... ejecutar pipeline ...
log_ejecucion['exito'] = True
log_ejecucion['archivos_generados'] = ['modelo.pkl', 'reporte.html']
guardar_log_ejecucion(log_ejecucion)

"""# 1.5 Ejercicio 4: Dashboard Interactivo con Streamlit Cloud

Paso 1: Configuración del Entorno Streamlit
"""

# Instala Streamlit si no está instalado
!pip install streamlit

# Importaciones necesarias
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pickle
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')
# Configuración de la página
st.set_page_config(
    page_title="RetailMax-Predictor de Ventas",
    page_icon=" ",
    layout="wide",
    initial_sidebar_state="expanded"
)
# CSS personalizado para mejorar la apariencia
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }
    .sidebar .sidebar-content {
        background-color: #f0f2f6;
    }
</style>
""", unsafe_allow_html=True)
print("Configuración inicial de Streamlit completada")

"""Paso 2: Función de Carga del Modelo"""

@st.cache_data
def cargar_datos_demo():
    """
    Carga datos de demostración para la app
    """
    # Crear datos sintéticos para demostración
    np.random.seed(42)
    tiendas = [f"Tienda_{i:02d}" for i in range(1, 21)]
    fechas = pd.date_range(start='2024-01-01', end='2024-03-15', freq='W')
    data = []
    for tienda in tiendas:
        for fecha in fechas:
            data.append({
                'tienda_id': tienda,
                'fecha': fecha,
                'ventas_semanales': np.random.normal(15000, 3000),
                'promocion_activa': np.random.choice([0, 1], p=[0.7, 0.3]),
                'inventario_inicial': np.random.normal(50000, 10000),
                'temperatura_promedio': np.random.normal(20, 8),
                'año': fecha.year,
                'mes': fecha.month,
                'semana': fecha.isocalendar().week,
                'dia_semana': fecha.dayofweek
            })
    return pd.DataFrame(data)
@st.cache_resource
def cargar_modelo_demo():
    """
    Carga o crea un modelo de demostración
    """
    # Para demostración, creamos un modelo simple
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.model_selection import train_test_split
    # Cargar datos
    df = cargar_datos_demo()
    # Preparar features
    feature_columns = ['promocion_activa', 'inventario_inicial', 'temperatura_promedio',
                       'año', 'mes', 'semana', 'dia_semana']
    X = df[feature_columns]
    y = df['ventas_semanales']
    # Entrenar modelo
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    modelo = RandomForestRegressor(n_estimators=100, random_state=42)
    modelo.fit(X_train, y_train)
    return modelo, feature_columns
# Cargar modelo y datos
modelo, feature_columns = cargar_modelo_demo()
df_historico = cargar_datos_demo()
st.success("Modelo y datos cargados exitosamente")

"""Paso 3: Sidebar con Controles de Entrada"""

def crear_sidebar():
    """
    Crea la barra lateral con controles de entrada
    """
    st.sidebar.markdown("##Configuración de Predicción")
    # Selección de tienda
    tiendas_disponibles = df_historico['tienda_id'].unique()
    tienda_seleccionada = st.sidebar.selectbox(
        "Selecciona la tienda:",
        options=tiendas_disponibles,
        help="Elige la tienda para la cual quieres hacer la predicción"
    )
    # Fecha de predicción
    fecha_prediccion = st.sidebar.date_input(
        "Fecha de la semana a predecir:",
        value=datetime.now() + timedelta(days=7),
        help="Selecciona la fecha de inicio de la semana"
    )
    # Promoción activa
    promocion_activa = st.sidebar.radio(
        "¿Habrá promoción activa?",
        options=[0, 1],
        format_func=lambda x: "No" if x == 0 else "Sí",
        help="Indica si habrá una promoción especial durante la semana"
    )
    # Inventario inicial
    inventario_inicial = st.sidebar.slider(
        "Inventario inicial (unidades):",
        min_value=20000,
        max_value=80000,
        value=50000,
        step=1000,
        help="Cantidad de productos disponibles al inicio de la semana"
    )
    # Temperatura promedio
    temperatura_promedio = st.sidebar.slider(
        "Temperatura promedio esperada (°C):",
        min_value=-10,
        max_value=40,
        value=20,
        step=1,
        help="Temperatura promedio esperada durante la semana"
    )
    # Botón de predicción
    predecir = st.sidebar.button(
        "Hacer Predicción",
        type="primary",
        help="Haz clic para generar la predicción con los parámetros seleccionados"
    )
    return {
        'tienda': tienda_seleccionada,
        'fecha': fecha_prediccion,
        'promocion': promocion_activa,
        'inventario': inventario_inicial,
        'temperatura': temperatura_promedio,
        'predecir': predecir
    }
# Crear sidebar
parametros = crear_sidebar()

"""Paso 4: Función de Predicción"""

def hacer_prediccion(parametros):
    """
    Realiza la predicción basada en los parámetros de entrada
    """
    # Preparar datos para predicción
    fecha = pd.to_datetime(parametros['fecha'])
    datos_prediccion = pd.DataFrame({
        'promocion_activa': [parametros['promocion']],
        'inventario_inicial': [parametros['inventario']],
        'temperatura_promedio': [parametros['temperatura']],
        'año': [fecha.year],
        'mes': [fecha.month],
        'semana': [fecha.isocalendar().week],
        'dia_semana': [fecha.dayofweek]
    })
    # Hacer predicción
    prediccion = modelo.predict(datos_prediccion)[0]
    # Calcular intervalo de confianza (simulado)
    std_error = prediccion * 0.15 # 15% de error estándar estimado
    intervalo_inferior = prediccion-1.96 * std_error
    intervalo_superior = prediccion + 1.96 * std_error
    return {
        'prediccion': prediccion,
        'intervalo_inferior': max(0, intervalo_inferior),
        'intervalo_superior': intervalo_superior,
        'confianza': 95
    }
def mostrar_resultados_prediccion(resultado, parametros):
    """
    Muestra los resultados de la predicción de manera atractiva
    """
    st.markdown("##Resultados de la Predicción")
    # Métricas principales
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric(
            label="Ventas Predichas",
            value=f"${resultado['prediccion']:,.0f}",
            help="Predicción puntual de ventas para la semana"
        )
    with col2:
        st.metric(
            label="Rango Mínimo",
            value=f"${resultado['intervalo_inferior']:,.0f}",
            help=f"Límite inferior del intervalo de confianza al {resultado['confianza']}%"
        )
    with col3:
        st.metric(
            label="Rango Máximo",
            value=f"${resultado['intervalo_superior']:,.0f}",
            help=f"Límite superior del intervalo de confianza al {resultado['confianza']}%"
        )
    # Gráfico de gauge
    fig_gauge = go.Figure(go.Indicator(
        mode = "gauge+number+delta",
        value = resultado['prediccion'],
        domain = {'x': [0, 1], 'y': [0, 1]},
        title = {'text': "Ventas Predichas ($)"},
        delta = {'reference': df_historico[df_historico['tienda_id'] == parametros['tienda']]['ventas_semanales'].mean()},
        gauge = {
            'axis': {'range': [None, 30000]},
            'bar': {'color': "darkblue"},
            'steps': [
                {'range': [0, 10000], 'color': "lightgray"},
                {'range': [10000, 20000], 'color': "gray"},
                {'range': [20000, 30000], 'color': "lightgreen"}
            ],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': resultado['prediccion']
            }
        }
    ))
    fig_gauge.update_layout(height=400)
    st.plotly_chart(fig_gauge, use_container_width=True)

"""Paso 5: Análisis Comparativo"""

def crear_analisis_comparativo(parametros, resultado):
    """
    Crea análisis comparativo con datos históricos
    """
    st.markdown("##Análisis Comparativo")
    # Filtrar datos históricos de la tienda
    datos_tienda = df_historico[df_historico['tienda_id'] == parametros['tienda']].copy()
    datos_tienda = datos_tienda.sort_values('fecha')
    # Crear gráfico de serie temporal
    fig_temporal = go.Figure()
    # Ventas históricas
    fig_temporal.add_trace(go.Scatter(
        x=datos_tienda['fecha'],
        y=datos_tienda['ventas_semanales'],
        mode='lines+markers',
        name='Ventas Históricas',
        line=dict(color='blue', width=2),
        marker=dict(size=6)
    ))
    # Predicción
    fig_temporal.add_trace(go.Scatter(
        x=[parametros['fecha']],
        y=[resultado['prediccion']],
        mode='markers',
        name='Predicción',
        marker=dict(color='red', size=12, symbol='star')
    ))
    # Intervalo de confianza
    fig_temporal.add_trace(go.Scatter(
        x=[parametros['fecha'], parametros['fecha']],
        y=[resultado['intervalo_inferior'], resultado['intervalo_superior']],
        mode='lines',
        name=f'Intervalo {resultado["confianza"]}%',
        line=dict(color='red', dash='dash'),
        showlegend=False
    ))
    fig_temporal.update_layout(
        title=f'Evolución de Ventas-{parametros["tienda"]}',
        xaxis_title='Fecha',
        yaxis_title='Ventas Semanales ($)',
        hovermode='x unified',
        height=500
    )
    st.plotly_chart(fig_temporal, use_container_width=True)
    # Estadísticas comparativas
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("### Estadísticas Históricas")
        promedio_historico = datos_tienda['ventas_semanales'].mean()
        std_historico = datos_tienda['ventas_semanales'].std()
        st.write(f"**Promedio histórico:** ${promedio_historico:,.0f}")
        st.write(f"**Desviación estándar:** ${std_historico:,.0f}")
        st.write(f"**Ventas máximas:** ${datos_tienda['ventas_semanales'].max():,.0f}")
        st.write(f"**Ventas mínimas:** ${datos_tienda['ventas_semanales'].min():,.0f}")
    with col2:
        st.markdown("### Comparación con Predicción")
        diferencia = resultado['prediccion']-promedio_historico
        porcentaje_diferencia = (diferencia / promedio_historico) * 100
        if diferencia > 0:
            st.success(f"**${diferencia:,.0f}** por encima del promedio ({porcentaje_diferencia:+.1f}%)")
        else:
            st.warning(f"**${abs(diferencia):,.0f}** por debajo del promedio ({porcentaje_diferencia:+.1f}%)")
        # Percentil de la predicción
        percentil = (datos_tienda['ventas_semanales'] < resultado['prediccion']).mean() * 100
        st.info(f"La predicción está en el **percentil {percentil:.0f}** de ventas históricas")
def crear_analisis_sensibilidad():
    """
    Crea análisis de sensibilidad para diferentes escenarios
    """
    st.markdown("## Análisis de Sensibilidad")
    st.markdown("Explora cómo diferentes factores afectan las predicciones:")
    # Análisis de promociones
    escenarios_promocion = []
    for promo in [0, 1]:
        datos_escenario = pd.DataFrame({
            'promocion_activa': [promo],
            'inventario_inicial': [50000],
            'temperatura_promedio': [20],
            'año': [2024],
            'mes': [3],
            'semana': [12],
            'dia_semana': [0]
        })
        pred = modelo.predict(datos_escenario)[0]
        escenarios_promocion.append({
            'Escenario': 'Con Promoción' if promo else 'Sin Promoción',
            'Ventas_Predichas': pred
        })
    df_promocion = pd.DataFrame(escenarios_promocion)
    fig_promocion = px.bar(
        df_promocion,
        x='Escenario',
        y='Ventas_Predichas',
        title='Impacto de las Promociones en las Ventas',
        color='Ventas_Predichas',
        color_continuous_scale='Blues'
    )
    fig_promocion.update_layout(height=400)
    st.plotly_chart(fig_promocion, use_container_width=True)
    # Mostrar diferencia
    diferencia_promocion = df_promocion.iloc[1]['Ventas_Predichas'] - df_promocion.iloc[0]['Ventas_Predichas']
    st.info(f"**Insight:** Las promociones aumentan las ventas en aproximadamente **${diferencia_promocion:,.0f}** ({(diferencia_promocion/df_promocion.iloc[0]['Ventas_Predichas']*100):+.1f}%)")

"""Paso 6: Página Principal de la App"""

def main():
    """
    Función principal de la aplicación
    """
    # Header principal
    st.markdown('<h1 class="main-header">RetailMax-Predictor de Ventas</h1>',unsafe_allow_html=True)
    st.markdown("""
    ### Bienvenido al Sistema de Predicción de Ventas
    Esta herramienta te permite predecir las ventas semanales de cualquier tienda RetailMax
    basándose en factores como promociones, inventario y condiciones climáticas.
    **Instrucciones:**
    1.Configura los parámetros en la barra lateral
    2.Haz clic en "Hacer Predicción"
    3.Analiza los resultados y comparaciones
    """)
    # Verificar si se debe hacer predicción
    if parametros['predecir']:
        with st.spinner('Generando predicción...'):
            resultado = hacer_prediccion(parametros)
            # Mostrar resultados
            mostrar_resultados_prediccion(resultado, parametros)
            # Análisis comparativo
            crear_analisis_comparativo(parametros, resultado)
            # Análisis de sensibilidad
            crear_analisis_sensibilidad()
            # Botón de descarga de resultados
            st.markdown("## Descargar Resultados")
            resultados_descarga = {
                'Tienda': parametros['tienda'],
                'Fecha_Prediccion': str(parametros['fecha']),
                'Promocion_Activa': 'Sí' if parametros['promocion'] else 'No',
                'Inventario_Inicial': parametros['inventario'],
                'Temperatura_Promedio': parametros['temperatura'],
                'Ventas_Predichas': f"${resultado['prediccion']:,.0f}",
                'Rango_Minimo': f"${resultado['intervalo_inferior']:,.0f}",
                'Rango_Maximo': f"${resultado['intervalo_superior']:,.0f}",
                'Timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            df_descarga = pd.DataFrame([resultados_descarga])
            csv_descarga = df_descarga.to_csv(index=False)
            st.download_button(
                label="Descargar Predicción (CSV)",
                data=csv_descarga,
                file_name=f"prediccion_ventas_{parametros['tienda']}_{parametros['fecha']}.csv",
                mime="text/csv"
            )
    else:
        # Mostrar información general cuando no hay predicción
        st.markdown("##Dashboard General")
        # Métricas generales
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total Tiendas", len(df_historico['tienda_id'].unique()))
        with col2:
            st.metric("Semanas de Datos", len(df_historico['fecha'].unique()))
        with col3:
            promedio_general = df_historico['ventas_semanales'].mean()
            st.metric("Promedio Ventas", f"${promedio_general:,.0f}")
        with col4:
            total_ventas = df_historico['ventas_semanales'].sum()
            st.metric("Ventas Totales", f"${total_ventas:,.0f}")
        # Gráfico de ventas por tienda
        ventas_por_tienda = df_historico.groupby('tienda_id')['ventas_semanales'].mean().sort_values(ascending=False)
        fig_tiendas = px.bar(
            x=ventas_por_tienda.index,
            y=ventas_por_tienda.values,
            title='Promedio de Ventas por Tienda',
            labels={'x': 'Tienda', 'y': 'Ventas Promedio ($)'}
        )
        fig_tiendas.update_layout(height=500)
        st.plotly_chart(fig_tiendas, use_container_width=True)
# Ejecutar aplicación principal
if __name__ == "__main__":
    main()